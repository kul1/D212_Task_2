from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

def run_pca_analysis(data, config):
    # Step 1: Standardize the data (excluding target column and non-numeric columns)
    print("\n### Step 1: Standardizing Data ###")

    # Drop non-numeric columns, assuming that any non-numeric column can be excluded
    numeric_data = data.select_dtypes(include=['float64', 'int64'])

    # Separate feature columns and target column
    feature_columns = [col for col in numeric_data.columns if col != config.TARGET_COLUMN]
    X = numeric_data[feature_columns]
    y = numeric_data[config.TARGET_COLUMN]  # Ensure the target column is numeric

    # Standardize the feature data
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Step 2: Perform PCA
    pca = PCA(n_components=config.PCA_COMPONENTS_RETAINED)
    X_pca = pca.fit_transform(X_scaled)

    print("\n### Step 2: Data After PCA ###")
    print(X_pca[:5])  # Print first 5 rows after PCA transformation

    # Step 3: Split data into train and test
    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=config.TEST_SIZE, random_state=config.RANDOM_STATE)

    # Step 4: Train KNN classifier
    knn = KNeighborsClassifier(n_neighbors=config.KNN_CONFIG['n_neighbors'])
    knn.fit(X_train, y_train)

    # Step 5: Evaluate model
    score = knn.score(X_test, y_test)
    print(f"\n### Model Accuracy: {score:.2f}")

    return knn
